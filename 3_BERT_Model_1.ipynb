{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YntdfBea-24e"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIILW4GZ_DWE"
   },
   "source": [
    "\n",
    "\n",
    "*   BERT is an NLP model that has been design by Google\n",
    "*   It is considered as one of the most efficient algorithms\n",
    "*   It has been pre-trained on two corpuses (more than 3 billion words in total)\n",
    "*   Based on a mecanism called \"attention\" that helps putting word into context\n",
    "*   In this notebook, we are going to fine-tune the BERT model on our dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmJO_oLA2ejV"
   },
   "source": [
    "# 1 - Importing libraries and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maR0coq3F5rp"
   },
   "source": [
    "## 1.1 - Installing and importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-WkRpzNBKRZ"
   },
   "source": [
    "First, let's install the `transformers` library which contains thousands of pre-trained models, including BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19500,
     "status": "ok",
     "timestamp": 1617265579162,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "3E2AKlZ1kzNa",
    "outputId": "3608a472-ccca-4ea6-b914-f960171da177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: requests in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: sacremoses in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/hassanazhar/anaconda3/lib/python3.11/site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers) (2.8.2)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m495.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m897.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.11.1\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.1.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m570.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-macosx_10_9_x86_64.whl (37 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install emoji\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_wBm5n-nd3mz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 01:59:37.756631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation libraries\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import emoji\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# Scikit-learn packages\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Packages to define a BERT model\n",
    "from transformers import TFBertModel, BertTokenizerFast, BertConfig\n",
    "\n",
    "# Keras and TensorFlow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46273,
     "status": "ok",
     "timestamp": 1617265605956,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "CcGjMGCU8edq",
    "outputId": "6a599d4d-40fb-4cfb-b17c-575baab8d7fc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-colab\n",
      "  Using cached google-colab-1.0.0.tar.gz (72 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-auth~=1.4.0 (from google-colab)\n",
      "  Using cached google_auth-1.4.2-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ipykernel~=4.6.0 (from google-colab)\n",
      "  Using cached ipykernel-4.6.1-py3-none-any.whl.metadata (981 bytes)\n",
      "Collecting ipython~=5.5.0 (from google-colab)\n",
      "  Using cached ipython-5.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting notebook~=5.2.0 (from google-colab)\n",
      "  Using cached notebook-5.2.2-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting six~=1.12.0 (from google-colab)\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pandas~=0.24.0 (from google-colab)\n",
      "  Using cached pandas-0.24.2.tar.gz (11.8 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[179 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/bh/phg5j6rx557fc31zr9pgztnr0000gn/T/pip-install-yjmzcqy5/pandas_5e1ac35ea8c44e99842587775d0b70bb/setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  \u001b[31m   \u001b[0m   import pkg_resources\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/bh/phg5j6rx557fc31zr9pgztnr0000gn/T/pip-install-yjmzcqy5/pandas_5e1ac35ea8c44e99842587775d0b70bb/setup.py:50: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   _CYTHON_INSTALLED = ver >= LooseVersion(min_cython_ver)\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/bh/phg5j6rx557fc31zr9pgztnr0000gn/T/pip-install-yjmzcqy5/pandas_5e1ac35ea8c44e99842587775d0b70bb/setup.py:435: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   current_system = LooseVersion(platform.mac_ver()[0])\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/bh/phg5j6rx557fc31zr9pgztnr0000gn/T/pip-install-yjmzcqy5/pandas_5e1ac35ea8c44e99842587775d0b70bb/setup.py:436: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   python_target = LooseVersion(\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/parsers.pyx:1764:34: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:158:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:160:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:162:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:164:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:166:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:168:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:170:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:174:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:176:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:178:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:180:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:183:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:185:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:189:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:191:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:193:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:195:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:197:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:199:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:203:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:205:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:207:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:209:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:211:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:213:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:217:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:219:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:221:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:223:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:225:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:227:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:231:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:233:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:235:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:237:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:239:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:241:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:245:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:247:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:249:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:251:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:254:23: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:256:23: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:259:19: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:262:15: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:521:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:522:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:527:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:528:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:533:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:534:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:539:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:540:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:548:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:549:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:554:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:555:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:560:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:561:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:566:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:567:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:575:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:576:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:581:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:582:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:587:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:588:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:593:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:594:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:602:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:603:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:608:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:609:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:614:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:615:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:623:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:624:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:629:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:630:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:635:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:636:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:641:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslibs/period.pyx:642:29: Casting a GIL-requiring function into a nogil function circumvents GIL validation\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslib.pyx:720:49: Buffer unpacking not optimized away.\n",
      "  \u001b[31m   \u001b[0m warning: pandas/_libs/tslib.pyx:720:49: Buffer unpacking not optimized away.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/algos.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/groupby.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/hashing.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/hashtable.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/index.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/internals.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/interval.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/join.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/lib.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/missing.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/parsers.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/reduction.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/ops.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/properties.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/reshape.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/skiplist.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/math.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/sparse.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslib.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/ccalendar.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/conversion.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/fields.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/frequencies.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/nattype.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/np_datetime.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/offsets.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/parsing.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/period.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/time.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/resolution.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/strptime.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/timedeltas.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/timestamps.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/tslibs/timezones.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/window.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libcpp/deque.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/_libs/writers.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/io/msgpack/_packer.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m Compiling pandas/io/msgpack/_unpacker.pyx because it depends on /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/Cython/Includes/libc/string.pxd.\n",
      "  \u001b[31m   \u001b[0m [ 1/36] Cythonizing pandas/_libs/algos.pyx\n",
      "  \u001b[31m   \u001b[0m [ 2/36] Cythonizing pandas/_libs/parsers.pyx\n",
      "  \u001b[31m   \u001b[0m [ 3/36] Cythonizing pandas/_libs/skiplist.pyx\n",
      "  \u001b[31m   \u001b[0m [ 4/36] Cythonizing pandas/_libs/tslibs/period.pyx\n",
      "  \u001b[31m   \u001b[0m [ 5/36] Cythonizing pandas/_libs/window.pyx\n",
      "  \u001b[31m   \u001b[0m [ 6/36] Cythonizing pandas/io/msgpack/_unpacker.pyx\n",
      "  \u001b[31m   \u001b[0m [ 7/36] Cythonizing pandas/_libs/groupby.pyx\n",
      "  \u001b[31m   \u001b[0m [ 8/36] Cythonizing pandas/_libs/hashing.pyx\n",
      "  \u001b[31m   \u001b[0m [ 9/36] Cythonizing pandas/_libs/hashtable.pyx\n",
      "  \u001b[31m   \u001b[0m [10/36] Cythonizing pandas/_libs/index.pyx\n",
      "  \u001b[31m   \u001b[0m [11/36] Cythonizing pandas/_libs/internals.pyx\n",
      "  \u001b[31m   \u001b[0m [12/36] Cythonizing pandas/_libs/interval.pyx\n",
      "  \u001b[31m   \u001b[0m [13/36] Cythonizing pandas/_libs/join.pyx\n",
      "  \u001b[31m   \u001b[0m [14/36] Cythonizing pandas/_libs/lib.pyx\n",
      "  \u001b[31m   \u001b[0m [15/36] Cythonizing pandas/_libs/missing.pyx\n",
      "  \u001b[31m   \u001b[0m [16/36] Cythonizing pandas/_libs/ops.pyx\n",
      "  \u001b[31m   \u001b[0m [17/36] Cythonizing pandas/_libs/properties.pyx\n",
      "  \u001b[31m   \u001b[0m [18/36] Cythonizing pandas/_libs/reduction.pyx\n",
      "  \u001b[31m   \u001b[0m [19/36] Cythonizing pandas/_libs/reshape.pyx\n",
      "  \u001b[31m   \u001b[0m [20/36] Cythonizing pandas/_libs/sparse.pyx\n",
      "  \u001b[31m   \u001b[0m [21/36] Cythonizing pandas/_libs/tslib.pyx\n",
      "  \u001b[31m   \u001b[0m [22/36] Cythonizing pandas/_libs/tslibs/ccalendar.pyx\n",
      "  \u001b[31m   \u001b[0m [23/36] Cythonizing pandas/_libs/tslibs/conversion.pyx\n",
      "  \u001b[31m   \u001b[0m [24/36] Cythonizing pandas/_libs/tslibs/fields.pyx\n",
      "  \u001b[31m   \u001b[0m [25/36] Cythonizing pandas/_libs/tslibs/frequencies.pyx\n",
      "  \u001b[31m   \u001b[0m [26/36] Cythonizing pandas/_libs/tslibs/nattype.pyx\n",
      "  \u001b[31m   \u001b[0m [27/36] Cythonizing pandas/_libs/tslibs/np_datetime.pyx\n",
      "  \u001b[31m   \u001b[0m [28/36] Cythonizing pandas/_libs/tslibs/offsets.pyx\n",
      "  \u001b[31m   \u001b[0m [29/36] Cythonizing pandas/_libs/tslibs/parsing.pyx\n",
      "  \u001b[31m   \u001b[0m [30/36] Cythonizing pandas/_libs/tslibs/resolution.pyx\n",
      "  \u001b[31m   \u001b[0m [31/36] Cythonizing pandas/_libs/tslibs/strptime.pyx\n",
      "  \u001b[31m   \u001b[0m [32/36] Cythonizing pandas/_libs/tslibs/timedeltas.pyx\n",
      "  \u001b[31m   \u001b[0m [33/36] Cythonizing pandas/_libs/tslibs/timestamps.pyx\n",
      "  \u001b[31m   \u001b[0m [34/36] Cythonizing pandas/_libs/tslibs/timezones.pyx\n",
      "  \u001b[31m   \u001b[0m [35/36] Cythonizing pandas/_libs/writers.pyx\n",
      "  \u001b[31m   \u001b[0m [36/36] Cythonizing pandas/io/msgpack/_packer.pyx\n",
      "  \u001b[31m   \u001b[0m /Users/hassanazhar/anaconda3/lib/python3.11/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m error in pandas setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)\n",
      "  \u001b[31m   \u001b[0m     pytz >= 2011k\n",
      "  \u001b[31m   \u001b[0m          ~~~~~~~^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6SjRuZCGQq7"
   },
   "source": [
    "## 1.2 - Loading datasets and lists of emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4GNLM5oEOKu"
   },
   "source": [
    "First, let's load our clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49306,
     "status": "ok",
     "timestamp": 1617265609000,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "kXcnOj1nlnrb",
    "outputId": "2a91b512-4a56-417e-e64c-e269b5ee6524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 29)\n",
      "(5426, 29)\n",
      "(5427, 29)\n"
     ]
    }
   ],
   "source": [
    "# Importing train, validation and test datasets with preprocessed texts and labels\n",
    "train_GE = pd.read_csv(\"data/train_clean.csv\")\n",
    "val_GE = pd.read_csv(\"data/val_clean.csv\")\n",
    "test_GE = pd.read_csv(\"data/test_clean.csv\")\n",
    "\n",
    "# Shape validation\n",
    "print(train_GE.shape)\n",
    "print(val_GE.shape)\n",
    "print(test_GE.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpawvOCVEgCd"
   },
   "source": [
    "Let's also load the lits of emotions from GoEmotions and Ekman taxonomies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50464,
     "status": "ok",
     "timestamp": 1617265610169,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "HKI8gFsUEayQ",
    "outputId": "5f709fd0-e8f3-4125-dba0-d85d75e0bb6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions on GoEmotions taxonomy are : \n",
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "\n",
      "Emotions on Ekman taxonomy are : \n",
      "['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# Loading emotion labels for GoEmotions taxonomy\n",
    "with open(\"data/emotions.txt\", \"r\") as file:\n",
    "    GE_taxonomy = file.read().split(\"\\n\")\n",
    "print(\"Emotions on GoEmotions taxonomy are : \\n{}\".format(GE_taxonomy))\n",
    "\n",
    "print()\n",
    "\n",
    "# Loading emotion labels for Ekman taxonomy\n",
    "with open(\"data/ekman_labels.txt\", \"r\") as file:\n",
    "    Ekman_taxonomy = file.read().split(\"\\n\")\n",
    "print(\"Emotions on Ekman taxonomy are : \\n{}\".format(Ekman_taxonomy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHTh1kSTHOQ7"
   },
   "source": [
    "#2 - Modeling : BERT (Bidirectional Encoder Representations from Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwNGgNJ8Gx_X"
   },
   "source": [
    "Now we can go ahead and start defining our BERT-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjvKpAysH1a3"
   },
   "source": [
    "##2.1 - Configuration of the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-8Fdf8PHC8d"
   },
   "source": [
    "First of all, let's define a `max_length` variable. This variable sets a fixed length of sequences to be fed to our model. Therefore, sequences will be either truncated if larger than this value, or completed using padding if smaller. To avoid truncating, we fix this value according to the largest sample of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50455,
     "status": "ok",
     "timestamp": 1617265610171,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "BBY58cNul4aH",
    "outputId": "f157b342-c2c0-41e9-b6c6-ab8d7776a7ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing max length of samples\n",
    "full_text = pd.concat([train_GE['Clean_text'], val_GE['Clean_text'], test_GE['Clean_text']])\n",
    "max_length = full_text.apply(lambda x: len(x.split())).max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdTKxbwTH8SF"
   },
   "source": [
    "We are going to use BERT's base model which contains almost 110 M trainable parameters. \n",
    "\n",
    "Also, in order to match the tokenization and vocabulary used during the training, we are going to use a BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367,
     "referenced_widgets": [
      "56923b6b0cbb4684a339b4c8442d8218",
      "4c7cd71c58db4ff2b7fd4754d1329cb1",
      "dbe0a2e764b3451ea2c957da9c81e073",
      "c1a0a146fb9e4fc6a84facf2083f7d98",
      "c987eefbd5a8430db6f63acfe48101c0",
      "7a28458037764a9e8f61db762ee76cc7",
      "f94affeea44241bd893e765d3b2595b5",
      "7cf4075f35ac43189f825750e6e31a37",
      "ab7f06259de4475bb56ea30a587a0519",
      "2bf7f059050440aeae93abb56da42b1b",
      "b3e5e15756314e028c70c8ad509b6d45",
      "74d0060c2b26467aab98203f3b6e8862",
      "ee2f0e3c9c2e4413ba5eddb51a41eac0",
      "49bd642db157433a818e87ce344ca788",
      "4449518347a34555b2e43c20f659368b",
      "408795dbb77949c688a01ceb57cd79e9",
      "8f8c296ed2cf456f909c79d7494e5717",
      "33c444e0f6db4bb889467904e4f5f373",
      "3d00e9bb66e64d3b8a02b4e4dd7fa0ec",
      "df007a65916644b7a0e12be1486eb929",
      "2b84bc188e3a42a485e373a2f082eb62",
      "8829af6fbe824bdea68c20f77832b273",
      "b6a33cd8ac9b402b92fdde2531784017",
      "16ae3f272e7f48f1aa952facfa90103f",
      "bdd01bb70693405fbc328fe08a95abb8",
      "60f8aefb1ef347d0a024233e44446e79",
      "526ed138b21243b8bb1372705ac54c31",
      "8eb3aea2b7614e509b9442c4f12079e5",
      "e530400c3d7944a9bb3de631be97c20c",
      "1452cca9f6044bb29988a30e16bd6512",
      "5e380424f69d4fe48c21aa10a76d04df",
      "5a902f789e6c4fdfb8278e217aaa1fd4",
      "9d7b1e07c28b4cbba335b6cee88e837d",
      "d94670a4d92d4ab3813fe383e72a8ce2",
      "a2f698fad1064038a7769c35fbe386c3",
      "462877f3796041f49f37ff8a64c691aa",
      "cc3375dda156477a8d88db87aa922728",
      "399699282bb54551af159c7fd36e3308",
      "5a6057df67dd44e0b623e071cbbea13e",
      "51b7374eaa984aca811ff234a88e69aa"
     ]
    },
    "executionInfo": {
     "elapsed": 87430,
     "status": "ok",
     "timestamp": 1617265647157,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "867vqvnTmI_F",
    "outputId": "ac86ff6c-fd34-476c-d1d5-e3efe4903d5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc68757e86943bb8944cc95966141b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9be06d4b8b94b49b3aa270c49730e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc9ea7b33bb45769e41373795b8624e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0ba27bdcc2469497ef714cbd507485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b327b43252f04a1daa54de31bf621ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Importing BERT pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=False)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "transformer_model = TFBertModel.from_pretrained(model_name, config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OHqPiqVIhB9"
   },
   "source": [
    "## 2.2 - Definition of the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsNfi4DxJdtC"
   },
   "source": [
    "Now that everything is in place, we can create a model based on BERT's main layer, and replace the top layers to reach our main objective (multi-label classification accross 28 possible emotions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1eM3XtfKFvm"
   },
   "source": [
    "Our model takes three inputs that result from tokenization:\n",
    "\n",
    "*   `input_ids`: indices of input sequence tokens in the vocabulary\n",
    "*   `token_ids`: Segment token indices to indicate first and second portions of the inputs.   0 for sentence A and 1 for sentence B\n",
    "*   `attention mask`: Mask to avoid performing attention on padding token indices.  0 for masked and 1 for not masked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gqxw9LYjm58O"
   },
   "outputs": [],
   "source": [
    "# function for creating BERT based model\n",
    "def create_model(nb_labels):\n",
    "\n",
    "  # Load the MainLayer\n",
    "  bert = transformer_model.layers[0]\n",
    "\n",
    "  # Build the model inputs\n",
    "  input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "  attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32')\n",
    "  token_ids = Input(shape=(max_length,), name='token_ids', dtype='int32')\n",
    "  inputs = {'input_ids': input_ids, 'attention_mask': attention_mask, 'token_ids': token_ids}\n",
    "\n",
    "  # Load the Transformers BERT model as a layer in a Keras model\n",
    "  bert_model = bert(inputs)[1]\n",
    "  dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
    "  pooled_output = dropout(bert_model, training=False)\n",
    "\n",
    "  # Then build the model output\n",
    "  emotion = Dense(units=nb_labels, activation=\"sigmoid\", kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='emotion')(pooled_output)\n",
    "  outputs = emotion\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSJJ5d6VNNvh"
   },
   "source": [
    "We use here a `sigmoid` activation function in the last dense layer that is better suited than a `softmax` activation function. In fact, `softmax` shrinks output probabilities for each label so that the sum of probabilities is 1. In our case, each label (emotion) can independently have a probability between 0 and 1, and `sigmoid` allows that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAA-SpCMOFpf"
   },
   "source": [
    "We can now create our model using 28 labels and visualize a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91889,
     "status": "ok",
     "timestamp": 1617265651635,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "rGW1AxI0nIxK",
    "outputId": "038e9af0-0715-4ea8-df7e-7b2b925a4289"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids={'input_ids': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=input_ids>', 'attention_mask': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=attention_mask>', 'token_ids': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=token_ids>'}\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a model instance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(\u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Take a look at the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(nb_labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: input_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: attention_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: token_ids}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load the Transformers BERT model as a layer in a Keras model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m bert(inputs)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m dropout \u001b[38;5;241m=\u001b[39m Dropout(config\u001b[38;5;241m.\u001b[39mhidden_dropout_prob, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpooled_output\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m dropout(bert_model, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:561\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(main_input) \u001b[38;5;129;01mor\u001b[39;00m main_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids={'input_ids': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=input_ids>', 'attention_mask': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=attention_mask>', 'token_ids': '<KerasTensor shape=(None, 48), dtype=int32, sparse=None, name=token_ids>'}\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "# Creating a model instance\n",
    "model = create_model(28)\n",
    "\n",
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNVRanuLI_8j"
   },
   "source": [
    "##2.3 - Data preprocessing and model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAIwoQYvJKQb"
   },
   "source": [
    "###2.3.1 - Tokenizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbfABovvO8f6"
   },
   "source": [
    "Let's go ahead and process our data. We will first separate texts from labels in the train, validation and test datasets, and then tokenize the texts using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XAopOFF1nzUS"
   },
   "outputs": [],
   "source": [
    "# Creating train, validation and test variables\n",
    "X_train = train_GE['Clean_text']\n",
    "y_train = train_GE.loc[:, GE_taxonomy].values.astype(float)\n",
    "\n",
    "X_val = val_GE['Clean_text']\n",
    "y_val = val_GE.loc[:, GE_taxonomy].values.astype(float)\n",
    "\n",
    "X_test = test_GE['Clean_text']\n",
    "y_test = test_GE.loc[:, GE_taxonomy].values.astype(float)\n",
    "\n",
    "# Tokenizing train data\n",
    "train_token = tokenizer(\n",
    "    text = X_train.to_list(),\n",
    "    add_special_tokens = True,\n",
    "    max_length = max_length,\n",
    "    truncation = True,\n",
    "    padding = 'max_length', \n",
    "    return_tensors = 'tf',\n",
    "    return_token_type_ids = True,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "# Tokenizing valisation data\n",
    "val_token = tokenizer(\n",
    "    text = X_val.to_list(),\n",
    "    add_special_tokens = True,\n",
    "    max_length = max_length,\n",
    "    truncation = True,\n",
    "    padding = 'max_length', \n",
    "    return_tensors = 'tf',\n",
    "    return_token_type_ids = True,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "# Tokenizing test data\n",
    "test_token = tokenizer(\n",
    "    text = X_test.to_list(),\n",
    "    add_special_tokens = True,\n",
    "    max_length = max_length,\n",
    "    truncation = True,\n",
    "    padding = 'max_length', \n",
    "    return_tensors = 'tf',\n",
    "    return_token_type_ids = True,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HMhCqsYipbys"
   },
   "outputs": [],
   "source": [
    "# Creating BERT compatible inputs with Input Ids, attention masks and token Ids \n",
    "train = {'input_ids': train_token['input_ids'], 'attention_mask': train_token['attention_mask'],'token_ids': train_token['token_type_ids']}\n",
    "val = {'input_ids': val_token['input_ids'], 'attention_mask': val_token['attention_mask'],'token_ids': val_token['token_type_ids']}\n",
    "test = {'input_ids': test_token['input_ids'], 'attention_mask': test_token['attention_mask'],'token_ids': test_token['token_type_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex7HpdObPjHk"
   },
   "source": [
    "During the training phase, we our going to use batches of 16 samples. After each epoch, data will be shuffled. Let's create TensorFlow tensors accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "31_D_Novp1gd"
   },
   "outputs": [],
   "source": [
    "# Creating TF tensors\n",
    "train_tensor = tf.data.Dataset.from_tensor_slices((train, y_train)).shuffle(len(train)).batch(16)\n",
    "val_tensor = tf.data.Dataset.from_tensor_slices((val, y_val)).shuffle(len(val)).batch(16)\n",
    "test_tensor = tf.data.Dataset.from_tensor_slices((test, y_test)).shuffle(len(test)).batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_onjkMzaJfEZ"
   },
   "source": [
    "### 2.3.2 - Class weights for multi-label and custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5RVU6ArQyTa"
   },
   "source": [
    "Training requires to monitor the loss function and eventually some other metrics to see how the model behaves throughout the epochs.\n",
    "\n",
    "Therefore, we need to define a weighted loss function that takes into account  class weights in our multi-label case.\n",
    "\n",
    "First, we need to compute class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "id": "MswUN2pOxOor"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m         weights[i] \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m1.\u001b[39m], y_true[:, i])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weights\n\u001b[0;32m----> 9\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m calculating_class_weights(y_train)\n",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m, in \u001b[0;36mcalculating_class_weights\u001b[0;34m(y_true)\u001b[0m\n\u001b[1;32m      4\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([number_dim, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_dim):\n\u001b[0;32m----> 6\u001b[0m     weights[i] \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0.\u001b[39m,\u001b[38;5;241m1.\u001b[39m], y_true[:, i])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# Function for calculating multilabel class weights\n",
    "def calculating_class_weights(y_true):\n",
    "    number_dim = np.shape(y_true)[1]\n",
    "    weights = np.empty([number_dim, 2])\n",
    "    for i in range(number_dim):\n",
    "        weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n",
    "    return weights\n",
    "\n",
    "class_weights = calculating_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dXWrQ2rSyTz"
   },
   "source": [
    "Then, we can define a custom crossentropy function in which we multiply the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOkmlU6f1K0z"
   },
   "outputs": [],
   "source": [
    "# Custom loss function for multilabel\n",
    "def get_weighted_loss(weights):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLp0d2ITJ3Eq"
   },
   "source": [
    "###2.3.3 - Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytcJQCODTyl4"
   },
   "source": [
    "Everything is ready, we can now start training our model.\n",
    "\n",
    "We chose not to exceed 4 epochs to train our model as it will most likely start to overfit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4010040,
     "status": "ok",
     "timestamp": 1617269569835,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "citzyDt1qOVq",
    "outputId": "de48f428-8b88-4aeb-c845-e642d2f92028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2714/2714 [==============================] - 995s 360ms/step - loss: 0.5013 - val_loss: 0.3536\n",
      "Epoch 2/4\n",
      "2714/2714 [==============================] - 975s 359ms/step - loss: 0.3183 - val_loss: 0.3361\n",
      "Epoch 3/4\n",
      "2714/2714 [==============================] - 971s 358ms/step - loss: 0.2462 - val_loss: 0.3729\n",
      "Epoch 4/4\n",
      "2714/2714 [==============================] - 973s 358ms/step - loss: 0.2041 - val_loss: 0.4143\n"
     ]
    }
   ],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5.e-05,\n",
    "    )\n",
    "\n",
    "# Set loss\n",
    "loss = get_weighted_loss(class_weights)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_tensor, \n",
    "                    epochs=4, \n",
    "                    validation_data=val_tensor,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4znNuCgxRUuv"
   },
   "source": [
    "## 2.4 - Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rw2Ovil8cw1M"
   },
   "source": [
    "### 2.4.1 - Evaluation on GoEmotions taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txhLFoByV53b"
   },
   "source": [
    "Let's generate predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrVVKNF9VjAN"
   },
   "outputs": [],
   "source": [
    "# Making probability predictions on test data\n",
    "y_pred_proba = model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEXHXyhPWCCr"
   },
   "source": [
    "When making predictions, we only generate probabilities associated with each label. To predict actual labels, we need to add an additional step that transforms these probabilities into labels given a certain threshold.\n",
    "\n",
    "We define a function to do so with a default threshold set to 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdlRK7nt2Jr8"
   },
   "outputs": [],
   "source": [
    "# from probabilities to labels using a given threshold\n",
    "def proba_to_labels(y_pred_proba, threshold=0.8):\n",
    "    \n",
    "    y_pred_labels = np.zeros_like(y_pred_proba)\n",
    "    \n",
    "    for i in range(y_pred_proba.shape[0]):\n",
    "        for j in range(y_pred_proba.shape[1]):\n",
    "            if y_pred_proba[i][j] > threshold:\n",
    "                y_pred_labels[i][j] = 1\n",
    "            else:\n",
    "                y_pred_labels[i][j] = 0\n",
    "                \n",
    "    return y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRzQNJ8bXWP9"
   },
   "outputs": [],
   "source": [
    "# Generate labels\n",
    "y_pred_labels = proba_to_labels(y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07pAgsrBWr2g"
   },
   "source": [
    "Let's evaluate these predictions using the evaluation function we defined in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwgSu5mdW_S9"
   },
   "outputs": [],
   "source": [
    "# Model evaluation function \n",
    "def model_eval(y_true, y_pred_labels, emotions):\n",
    "    \n",
    "    # Defining variables\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    # Per emotion evaluation      \n",
    "    idx2emotion = {i: e for i, e in enumerate(emotions)}\n",
    "    \n",
    "    for i in range(len(emotions)):\n",
    "   \n",
    "        # Computing precision, recall and f1-score\n",
    "        p, r, f1_score, _ = precision_recall_fscore_support(y_true[:, i], y_pred_labels[:, i], average=\"binary\")\n",
    "        \n",
    "        # Append results in lists\n",
    "        precision.append(round(p, 2))\n",
    "        recall.append(round(r, 2))\n",
    "        f1.append(round(f1_score, 2))\n",
    "    \n",
    "    # Macro evaluation\n",
    "    macro_p, macro_r, macro_f1_score, _ = precision_recall_fscore_support(y_true, y_pred_labels, average=\"macro\")\n",
    "    \n",
    "    # Append results in lists\n",
    "    precision.append(round(macro_p, 2))\n",
    "    recall.append(round(macro_r, 2))\n",
    "    f1.append(round(macro_f1_score, 2))\n",
    "    \n",
    "    # Converting results to a dataframe\n",
    "    df_results = pd.DataFrame({\"Precision\":precision, \"Recall\":recall, 'F1':f1})\n",
    "    df_results.index = emotions+['MACRO-AVERAGE']\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1617269651951,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "rW_rNrE_cN56",
    "outputId": "4ffe84ae-9434-4233-e00d-f8d8ae90183d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACRO-AVERAGE</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall    F1\n",
       "admiration           0.62    0.68  0.65\n",
       "amusement            0.71    0.94  0.81\n",
       "anger                0.33    0.65  0.44\n",
       "annoyance            0.26    0.52  0.35\n",
       "approval             0.32    0.47  0.38\n",
       "caring               0.28    0.54  0.37\n",
       "confusion            0.22    0.77  0.34\n",
       "curiosity            0.40    0.84  0.55\n",
       "desire               0.24    0.82  0.37\n",
       "disappointment       0.19    0.42  0.27\n",
       "disapproval          0.27    0.64  0.38\n",
       "disgust              0.25    0.74  0.37\n",
       "embarrassment        0.16    0.54  0.24\n",
       "excitement           0.17    0.65  0.28\n",
       "fear                 0.35    0.85  0.49\n",
       "gratitude            0.77    0.94  0.85\n",
       "grief                0.16    0.67  0.26\n",
       "joy                  0.24    0.81  0.37\n",
       "love                 0.65    0.94  0.77\n",
       "nervousness          0.12    0.61  0.20\n",
       "optimism             0.38    0.64  0.48\n",
       "pride                0.09    0.50  0.15\n",
       "realization          0.20    0.39  0.26\n",
       "relief               0.06    0.91  0.12\n",
       "remorse              0.47    0.89  0.61\n",
       "sadness              0.40    0.65  0.49\n",
       "surprise             0.36    0.69  0.47\n",
       "neutral              0.76    0.39  0.51\n",
       "MACRO-AVERAGE        0.34    0.68  0.42"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "model_eval(y_test, y_pred_labels, GE_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHKrdAGgzzxL"
   },
   "source": [
    "As we can see, this model outperformed the baseline model. But we can make some improvements ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiEfmN4zYWzp"
   },
   "source": [
    "### 2.4.2 - Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJBpGoXFYmqX"
   },
   "source": [
    "In the initial evaluation, we set an aribitrary threshold. However, we can also choose a threshold that maximizes a certain metric. \n",
    "\n",
    "We define a function that tests a certain number of possible thresholds, and returns the best threshold together with the best predicted labels and best macro f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVoNZ3FsNZ_W"
   },
   "outputs": [],
   "source": [
    "# Function that computes labels from probabilities and optimizes the threshold that maximizes f1-score\n",
    "def proba_to_labels_opt(y_true, y_pred_proba):\n",
    "    \n",
    "    '''\n",
    "    Inputs:\n",
    "        y_true: Ground truth labels\n",
    "        y_pred_proba: predicted probabilities\n",
    "        \n",
    "    Outputs :\n",
    "        best_y_pred_labels: preticted labels associated with best threshold\n",
    "        best_t: best threshold\n",
    "        best_macro_f1: macro f1-score associated with predicted labels\n",
    "    '''\n",
    "    \n",
    "    # range of possible thresholds\n",
    "    thresholds = np.arange(0.7, 0.99, 0.01)\n",
    "    \n",
    "    # Computing threshold that maximizes macro f1-score \n",
    "    best_y_pred_labels = np.zeros_like(y_pred_proba)\n",
    "    best_t = 0\n",
    "    best_macro_f1 = 0\n",
    "    \n",
    "    # Iterating through possible thresholds\n",
    "    for t in thresholds:\n",
    "        \n",
    "        y_pred_labels = proba_to_labels(y_pred_proba, t)\n",
    "                             \n",
    "        _, _, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average=\"macro\")\n",
    "        \n",
    "        if macro_f1 > best_macro_f1:\n",
    "            best_macro_f1 = macro_f1\n",
    "            best_t = t\n",
    "            best_y_pred_labels = y_pred_labels\n",
    "            \n",
    "    return best_y_pred_labels, best_t, best_macro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6S8iogIb051"
   },
   "source": [
    "We can now apply this function to our predicted probabilities and compute optimized label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13668,
     "status": "ok",
     "timestamp": 1617269754028,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "3LDKmAidZvIi",
    "outputId": "55dafad7-1dfd-4c8f-dd57-ae6d6fce71b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's threshold is 0.9200000000000002\n",
      "The model's best macro-f1 is 0.44630653234099465\n"
     ]
    }
   ],
   "source": [
    "# Compute label predictions and corresponding optimal thresholds \n",
    "y_pred_labels_opt, threshold_opt, macro_f1_opt = proba_to_labels_opt(y_test, y_pred_proba)\n",
    "print(\"The model's threshold is {}\".format(threshold_opt))\n",
    "print(\"The model's best macro-f1 is {}\".format(macro_f1_opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1617269764899,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "2TM1hZ1JZ31q",
    "outputId": "df2e8b00-083f-4b81-d095-842a188f402b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACRO-AVERAGE</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall    F1\n",
       "admiration           0.70    0.52  0.60\n",
       "amusement            0.77    0.86  0.81\n",
       "anger                0.43    0.52  0.47\n",
       "annoyance            0.40    0.17  0.24\n",
       "approval             0.47    0.25  0.33\n",
       "caring               0.35    0.37  0.36\n",
       "confusion            0.35    0.46  0.40\n",
       "curiosity            0.46    0.65  0.54\n",
       "desire               0.31    0.72  0.44\n",
       "disappointment       0.29    0.23  0.26\n",
       "disapproval          0.33    0.45  0.38\n",
       "disgust              0.32    0.60  0.42\n",
       "embarrassment        0.26    0.54  0.35\n",
       "excitement           0.26    0.59  0.36\n",
       "fear                 0.44    0.83  0.57\n",
       "gratitude            0.88    0.91  0.90\n",
       "grief                0.25    0.50  0.33\n",
       "joy                  0.36    0.73  0.48\n",
       "love                 0.69    0.88  0.77\n",
       "nervousness          0.19    0.48  0.27\n",
       "optimism             0.54    0.55  0.55\n",
       "pride                0.14    0.50  0.22\n",
       "realization          0.27    0.28  0.27\n",
       "relief               0.07    0.73  0.13\n",
       "remorse              0.54    0.86  0.66\n",
       "sadness              0.53    0.52  0.53\n",
       "surprise             0.44    0.65  0.53\n",
       "neutral              0.82    0.21  0.33\n",
       "MACRO-AVERAGE        0.42    0.56  0.45"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation : Precision, Recall, F-score\n",
    "model_eval(y_test, y_pred_labels_opt, GE_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMYPEVAK0D89"
   },
   "source": [
    "**Optimizing the threshold** helped us to **slightly improve** the model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPhDnnZXSOao"
   },
   "source": [
    "### 2.4.3 - Handling all \"0\" label predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI0srl-FcToA"
   },
   "source": [
    "Our threshold is relatively high. Therefore, our model predicted label probabilities for some samples that are all below this threshold. In other words, **our model did not detect any emotion for some samples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1617269796639,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "ouxzyJ-TOpLZ",
    "outputId": "6ab78852-8ace-4383-952c-5c06c88a293d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of predictions with no positive label\n",
    "sum(np.sum(y_pred_labels_opt, axis=1)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2QzGjtTco-Z"
   },
   "source": [
    "In this case, we can try two different strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoEIzOLdN_bo"
   },
   "source": [
    "#### a) No predictions means class with highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC3iEZfNcxPQ"
   },
   "source": [
    "The first possibility is to consider the **label with the highest** probability for these samples, ignoring the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1617269823371,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "5PVi0WsPUf2S",
    "outputId": "5c473793-3f39-41ac-9994-162adc14bc9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACRO-AVERAGE</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall    F1\n",
       "admiration           0.24    0.60  0.34\n",
       "amusement            0.77    0.86  0.81\n",
       "anger                0.43    0.52  0.47\n",
       "annoyance            0.40    0.17  0.24\n",
       "approval             0.47    0.25  0.33\n",
       "caring               0.35    0.37  0.36\n",
       "confusion            0.35    0.46  0.40\n",
       "curiosity            0.46    0.65  0.54\n",
       "desire               0.31    0.72  0.44\n",
       "disappointment       0.29    0.23  0.26\n",
       "disapproval          0.33    0.45  0.38\n",
       "disgust              0.32    0.60  0.42\n",
       "embarrassment        0.26    0.54  0.35\n",
       "excitement           0.26    0.59  0.36\n",
       "fear                 0.44    0.83  0.57\n",
       "gratitude            0.88    0.91  0.90\n",
       "grief                0.25    0.50  0.33\n",
       "joy                  0.36    0.73  0.48\n",
       "love                 0.69    0.88  0.77\n",
       "nervousness          0.19    0.48  0.27\n",
       "optimism             0.54    0.55  0.55\n",
       "pride                0.14    0.50  0.22\n",
       "realization          0.27    0.28  0.27\n",
       "relief               0.07    0.73  0.13\n",
       "remorse              0.54    0.86  0.66\n",
       "sadness              0.53    0.52  0.53\n",
       "surprise             0.44    0.65  0.53\n",
       "neutral              0.82    0.21  0.33\n",
       "MACRO-AVERAGE        0.41    0.56  0.44"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling empty predictions\n",
    "y_pred_labels_opt_h = np.copy(y_pred_labels_opt)\n",
    "\n",
    "# if no predictions ==> label with highest proba\n",
    "for i, pred in enumerate(y_pred_labels_opt_h):\n",
    "    if pred.sum()==0:\n",
    "        pred[np.argmax(y_pred_labels_opt[i])]=1\n",
    "\n",
    "# Evaluation\n",
    "model_eval(y_test, y_pred_labels_opt_h, GE_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj27hpsK08fb"
   },
   "source": [
    "This strategy did not pay off as we decreased the macro f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiQqOd3QOGBA"
   },
   "source": [
    "#### b) No predictions means \"Neutral\" emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0PST16pdAIR"
   },
   "source": [
    "The second possibility is to **assign the 'Neutral'** emotion given it is the most represented one. This strategy looks more natural as if we can't detect an emotion, it means it is Neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1617269859826,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "OO9E37UsPEte",
    "outputId": "4c57ba53-446f-4b5d-b30e-98b56fa5aaa1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admiration</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amusement</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annoyance</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approval</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caring</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desire</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointment</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapproval</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassment</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excitement</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grief</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nervousness</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pride</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realization</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relief</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remorse</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACRO-AVERAGE</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Precision  Recall    F1\n",
       "admiration           0.70    0.52  0.60\n",
       "amusement            0.77    0.86  0.81\n",
       "anger                0.43    0.52  0.47\n",
       "annoyance            0.40    0.17  0.24\n",
       "approval             0.47    0.25  0.33\n",
       "caring               0.35    0.37  0.36\n",
       "confusion            0.35    0.46  0.40\n",
       "curiosity            0.46    0.65  0.54\n",
       "desire               0.31    0.72  0.44\n",
       "disappointment       0.29    0.23  0.26\n",
       "disapproval          0.33    0.45  0.38\n",
       "disgust              0.32    0.60  0.42\n",
       "embarrassment        0.26    0.54  0.35\n",
       "excitement           0.26    0.59  0.36\n",
       "fear                 0.44    0.83  0.57\n",
       "gratitude            0.88    0.91  0.90\n",
       "grief                0.25    0.50  0.33\n",
       "joy                  0.36    0.73  0.48\n",
       "love                 0.69    0.88  0.77\n",
       "nervousness          0.19    0.48  0.27\n",
       "optimism             0.54    0.55  0.55\n",
       "pride                0.14    0.50  0.22\n",
       "realization          0.27    0.28  0.27\n",
       "relief               0.07    0.73  0.13\n",
       "remorse              0.54    0.86  0.66\n",
       "sadness              0.53    0.52  0.53\n",
       "surprise             0.44    0.65  0.53\n",
       "neutral              0.65    0.49  0.56\n",
       "MACRO-AVERAGE        0.42    0.57  0.45"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling empty predictions\n",
    "y_pred_labels_opt_n = np.copy(y_pred_labels_opt)\n",
    "\n",
    "# if no predictions ==> neutral\n",
    "for pred in y_pred_labels_opt_n:\n",
    "    if pred.sum()==0:\n",
    "        pred[-1]=1\n",
    "\n",
    "# Evaluation\n",
    "model_eval(y_test, y_pred_labels_opt_n, GE_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XPoQD3H1arH"
   },
   "source": [
    "Using this strategy helped us **slightly improve the macro precision and recall**, but **not enough to make a significant impact on the macro f1-score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAEYceuZT30x"
   },
   "source": [
    "### 2.4.4 - Indirect evaluation on Ekman taxonomy by mapping predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_pPXWzFeYzc"
   },
   "source": [
    "Until now, we have only evaluated our model on the GoEmotions taxonomy.\n",
    "\n",
    "As a reference, we can try to map the true and predicted emotions to the Ekman taxonomy and see how our model performs.\n",
    "\n",
    "We have already defined the Ekman taxonomy earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQetXmQPfOa1"
   },
   "source": [
    "Let's define a function that transforms labels from GoEmotions to Ekman taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KOWIXJUesiy"
   },
   "outputs": [],
   "source": [
    "# Function thats maps predictions on GoEmotions taxonomy to Ekman taxonomy\n",
    "def GE_to_Ekman(GE_labels):\n",
    "    \n",
    "    # Create a dataframe of GoEmotions labels\n",
    "    df_GE = pd.DataFrame(GE_labels, columns=GE_taxonomy)\n",
    "\n",
    "    # Create an empty dataframe of Ekman labels\n",
    "    df_Ekman  = pd.DataFrame(np.zeros((len(GE_labels), len(Ekman_taxonomy))), columns=Ekman_taxonomy)\n",
    "\n",
    "    for i in range(len(df_GE)):\n",
    "\n",
    "        if df_GE.loc[i,['anger', 'annoyance', 'disapproval']].sum() >= 1:\n",
    "            df_Ekman.loc[i,'anger'] = 1\n",
    "\n",
    "        if df_GE.loc[i,'disgust'].sum() >= 1:\n",
    "            df_Ekman.loc[i,'disgust'] = 1\n",
    "\n",
    "        if df_GE.loc[i,['fear', 'nervousness']].sum() >= 1:\n",
    "            df_Ekman.loc[i,'fear'] = 1\n",
    "\n",
    "        if df_GE.loc[i,['joy', 'amusement', 'approval', 'excitement', 'gratitude',\n",
    "                        'love', 'optimism', 'relief', 'pride', 'admiration', 'desire','caring']].sum() >= 1:\n",
    "            df_Ekman.loc[i,'joy'] = 1 \n",
    "\n",
    "        if df_GE.loc[i,'neutral'].sum() >= 1:\n",
    "            df_Ekman.loc[i,'neutral'] = 1\n",
    "\n",
    "        if df_GE.loc[i,['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse']].sum() >= 1:\n",
    "            df_Ekman.loc[i,'sadness'] = 1\n",
    "\n",
    "        if df_GE.loc[i,['surprise', 'realization', 'confusion', 'curiosity']].sum() >= 1:\n",
    "            df_Ekman.loc[i,'surprise'] = 1\n",
    "\n",
    "    return df_Ekman.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkZxJmVzgb4o"
   },
   "source": [
    "We can now apply our function and evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 52431,
     "status": "ok",
     "timestamp": 1617269969709,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "TmecGLKsez0Q",
    "outputId": "4380e5e1-1bc5-4a58-fe83-4ffd196ab75d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACRO-AVERAGE</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision  Recall    F1\n",
       "anger               0.54    0.47  0.50\n",
       "disgust             0.32    0.60  0.42\n",
       "fear                0.48    0.79  0.60\n",
       "joy                 0.78    0.82  0.80\n",
       "sadness             0.58    0.56  0.57\n",
       "surprise            0.54    0.66  0.59\n",
       "neutral             0.65    0.49  0.56\n",
       "MACRO-AVERAGE       0.55    0.63  0.58"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping GoEmotion labels to Ekman labels (true and predictions)\n",
    "y_test_Ekman = GE_to_Ekman(y_test)\n",
    "y_pred_labels_Ekman = GE_to_Ekman(y_pred_labels_opt_n)\n",
    "\n",
    "# Evaluation\n",
    "model_eval(y_test_Ekman, y_pred_labels_Ekman, Ekman_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_zEgspp13iW"
   },
   "source": [
    "Our model obtained a **reasonable score** on the Ekman taxonomy. However, we expected more when switching from 28 emotions to only 7 emotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_ojzWhTUT2W"
   },
   "source": [
    "## 2.5 - Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJABBqRVtlbk"
   },
   "source": [
    "To make predictions on a new sample, it needs to be processed using all the different precessing steps we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdTRJR_ZhVKI"
   },
   "outputs": [],
   "source": [
    "# Retrieving initial preprocessings\n",
    "def preprocess_corpus(x):\n",
    "    \n",
    "    # Adding a space between words and punctation\n",
    "    x = re.sub( r'([a-zA-Z\\[\\]])([,;.!?])', r'\\1 \\2', x)\n",
    "    x = re.sub( r'([,;.!?])([a-zA-Z\\[\\]])', r'\\1 \\2', x)\n",
    "\n",
    "    # Demojize\n",
    "    x = emoji.demojize(x)\n",
    "\n",
    "    # Expand contraction\n",
    "    x = contractions.fix(x)\n",
    "\n",
    "    # Lower\n",
    "    x = x.lower()\n",
    "\n",
    "    #correct some acronyms/typos/abbreviations  \n",
    "    x = re.sub(r\"lmao\", \"laughing my ass off\", x)  \n",
    "    x = re.sub(r\"amirite\", \"am i right\", x)\n",
    "    x = re.sub(r\"\\b(tho)\\b\", \"though\", x)\n",
    "    x = re.sub(r\"\\b(ikr)\\b\", \"i know right\", x)\n",
    "    x = re.sub(r\"\\b(ya|u)\\b\", \"you\", x)\n",
    "    x = re.sub(r\"\\b(eu)\\b\", \"europe\", x)\n",
    "    x = re.sub(r\"\\b(da)\\b\", \"the\", x)\n",
    "    x = re.sub(r\"\\b(dat)\\b\", \"that\", x)\n",
    "    x = re.sub(r\"\\b(dats)\\b\", \"that is\", x)\n",
    "    x = re.sub(r\"\\b(cuz)\\b\", \"because\", x)\n",
    "    x = re.sub(r\"\\b(fkn)\\b\", \"fucking\", x)\n",
    "    x = re.sub(r\"\\b(tbh)\\b\", \"to be honest\", x)\n",
    "    x = re.sub(r\"\\b(tbf)\\b\", \"to be fair\", x)\n",
    "    x = re.sub(r\"faux pas\", \"mistake\", x)\n",
    "    x = re.sub(r\"\\b(btw)\\b\", \"by the way\", x)\n",
    "    x = re.sub(r\"\\b(bs)\\b\", \"bullshit\", x)\n",
    "    x = re.sub(r\"\\b(kinda)\\b\", \"kind of\", x)\n",
    "    x = re.sub(r\"\\b(bruh)\\b\", \"bro\", x)\n",
    "    x = re.sub(r\"\\b(w/e)\\b\", \"whatever\", x)\n",
    "    x = re.sub(r\"\\b(w/)\\b\", \"with\", x)\n",
    "    x = re.sub(r\"\\b(w/o)\\b\", \"without\", x)\n",
    "    x = re.sub(r\"\\b(doj)\\b\", \"department of justice\", x)\n",
    "\n",
    "    # replace some words with multiple occurences of a letter, example \"coooool\" turns into --> cool\n",
    "    x = re.sub(r\"\\b(j+e{2,}z+e*)\\b\", \"jeez\", x)\n",
    "    x = re.sub(r\"\\b(co+l+)\\b\", \"cool\", x)\n",
    "    x = re.sub(r\"\\b(g+o+a+l+)\\b\", \"goal\", x)\n",
    "    x = re.sub(r\"\\b(s+h+i+t+)\\b\", \"shit\", x)\n",
    "    x = re.sub(r\"\\b(o+m+g+)\\b\", \"omg\", x)\n",
    "    x = re.sub(r\"\\b(w+t+f+)\\b\", \"wtf\", x)\n",
    "    x = re.sub(r\"\\b(w+h+a+t+)\\b\", \"what\", x)\n",
    "    x = re.sub(r\"\\b(y+e+y+|y+a+y+|y+e+a+h+)\\b\", \"yeah\", x)\n",
    "    x = re.sub(r\"\\b(w+o+w+)\\b\", \"wow\", x)\n",
    "    x = re.sub(r\"\\b(w+h+y+)\\b\", \"why\", x)\n",
    "    x = re.sub(r\"\\b(s+o+)\\b\", \"so\", x)\n",
    "    x = re.sub(r\"\\b(f)\\b\", \"fuck\", x)\n",
    "    x = re.sub(r\"\\b(w+h+o+p+s+)\\b\", \"whoops\", x)\n",
    "    x = re.sub(r\"\\b(ofc)\\b\", \"of course\", x)\n",
    "    x = re.sub(r\"\\b(the us)\\b\", \"usa\", x)\n",
    "    x = re.sub(r\"\\b(gf)\\b\", \"girlfriend\", x)\n",
    "    x = re.sub(r\"\\b(hr)\\b\", \"human ressources\", x)\n",
    "    x = re.sub(r\"\\b(mh)\\b\", \"mental health\", x)\n",
    "    x = re.sub(r\"\\b(idk)\\b\", \"i do not know\", x)\n",
    "    x = re.sub(r\"\\b(gotcha)\\b\", \"i got you\", x)\n",
    "    x = re.sub(r\"\\b(y+e+p+)\\b\", \"yes\", x)\n",
    "    x = re.sub(r\"\\b(a*ha+h[ha]*|a*ha +h[ha]*)\\b\", \"haha\", x)\n",
    "    x = re.sub(r\"\\b(o?l+o+l+[ol]*)\\b\", \"lol\", x)\n",
    "    x = re.sub(r\"\\b(o*ho+h[ho]*|o*ho +h[ho]*)\\b\", \"ohoh\", x)\n",
    "    x = re.sub(r\"\\b(o+h+)\\b\", \"oh\", x)\n",
    "    x = re.sub(r\"\\b(a+h+)\\b\", \"ah\", x)\n",
    "    x = re.sub(r\"\\b(u+h+)\\b\", \"uh\", x)\n",
    "\n",
    "    # Handling emojis\n",
    "    x = re.sub(r\"<3\", \" love \", x)\n",
    "    x = re.sub(r\"xd\", \" smiling_face_with_open_mouth_and_tightly_closed_eyes \", x)\n",
    "    x = re.sub(r\":\\)\", \" smiling_face \", x)\n",
    "    x = re.sub(r\"^_^\", \" smiling_face \", x)\n",
    "    x = re.sub(r\"\\*_\\*\", \" star_struck \", x)\n",
    "    x = re.sub(r\":\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\":\\^\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\";\\(\", \" frowning_face \", x)\n",
    "    x = re.sub(r\":\\/\",  \" confused_face\", x)\n",
    "    x = re.sub(r\";\\)\",  \" wink\", x)\n",
    "    x = re.sub(r\">__<\",  \" unamused \", x)\n",
    "    x = re.sub(r\"\\b([xo]+x*)\\b\", \" xoxo \", x)\n",
    "    x = re.sub(r\"\\b(n+a+h+)\\b\", \"no\", x)\n",
    "    \n",
    "    # Handling special cases of text\n",
    "    x = re.sub(r\"h a m b e r d e r s\", \"hamberders\", x)\n",
    "    x = re.sub(r\"b e n\", \"ben\", x)\n",
    "    x = re.sub(r\"s a t i r e\", \"satire\", x)\n",
    "    x = re.sub(r\"y i k e s\", \"yikes\", x)\n",
    "    x = re.sub(r\"s p o i l e r\", \"spoiler\", x)\n",
    "    x = re.sub(r\"thankyou\", \"thank you\", x)\n",
    "    x = re.sub(r\"a^r^o^o^o^o^o^o^o^n^d\", \"around\", x)\n",
    "\n",
    "    # Remove special characters and numbers replace by space + remove double space\n",
    "    x = re.sub(r\"\\b([.]{3,})\",\" dots \", x)\n",
    "    x = re.sub(r\"[^A-Za-z!?_]+\",\" \", x)\n",
    "    x = re.sub(r\"\\b([s])\\b *\",\"\", x)\n",
    "    x = re.sub(r\" +\",\" \", x)\n",
    "    x = x.strip()\n",
    "\n",
    "    return x     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5FLEtwj3P6C"
   },
   "source": [
    "Now we can define a prediction function that takes one or more samples, and outputs the detected emotions from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm-6OEi_1V6t"
   },
   "outputs": [],
   "source": [
    "def predict_samples(text_samples, model, threshold):\n",
    "    \n",
    "    # Text preprocessing and cleaning\n",
    "    text_samples_clean = [preprocess_corpus(text) for text in text_samples]\n",
    "    \n",
    "    # Tokenizing train data\n",
    "    samples_token = tokenizer(\n",
    "        text = text_samples_clean,\n",
    "        add_special_tokens = True,\n",
    "        max_length = max_length,\n",
    "        truncation = True,\n",
    "        padding = 'max_length', \n",
    "        return_tensors = 'tf',\n",
    "        return_token_type_ids = True,\n",
    "        return_attention_mask = True,\n",
    "        verbose = True,\n",
    "    )\n",
    "    \n",
    "    # Preparing to feed the model\n",
    "    samples = {'input_ids': samples_token['input_ids'],\n",
    "               'attention_mask': samples_token['attention_mask'],\n",
    "               'token_ids': samples_token['token_type_ids']\n",
    "              }\n",
    "    \n",
    "    # Probability predictions\n",
    "    samples_pred_proba = model.predict(samples)\n",
    "    \n",
    "    # Label prediction using threshold\n",
    "    samples_pred_labels = proba_to_labels(samples_pred_proba)\n",
    "    \n",
    "    # if no predictions ==> neutral\n",
    "    for pred in samples_pred_labels:\n",
    "        if pred.sum()==0:\n",
    "            pred[-1]=1\n",
    "            \n",
    "    samples_pred_labels_df = pd.DataFrame(samples_pred_labels)\n",
    "    samples_pred_labels_df = samples_pred_labels_df.apply(lambda x: [GE_taxonomy[i] for i in range(len(x)) if x[i]==1], axis=1)\n",
    "    \n",
    "    #return list(samples_pred_labels_df)\n",
    "    return pd.DataFrame({\"Text\":text_samples, \"Emotions\":list(samples_pred_labels_df)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iZXTQyW3W4L"
   },
   "source": [
    "Let's try on few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1617271107878,
     "user": {
      "displayName": "Ibrahim Benjelloun",
      "photoUrl": "",
      "userId": "05131578507394582340"
     },
     "user_tz": -120
    },
    "id": "rQ_dctb0O-9A",
    "outputId": "035da496-f3d0-4cad-fda4-6659f3117a16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[approval, joy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are you kiddin me ??!!</td>\n",
       "      <td>[confusion, curiosity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my advice is that you should see a doctor</td>\n",
       "      <td>[caring]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a dog in the park</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Emotions\n",
       "0  My favourite food is anything I didn't have to...         [approval, joy]\n",
       "1                             are you kiddin me ??!!  [confusion, curiosity]\n",
       "2          my advice is that you should see a doctor                [caring]\n",
       "3                                  a dog in the park               [neutral]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict samples\n",
    "predict_samples([\"My favourite food is anything I didn't have to cook myself\", \"are you kiddin me ??!!\", \"my advice is that you should see a doctor\", \"a dog in the park\"], model, threshold_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWFLQoJR34fk"
   },
   "source": [
    "As we can see, **the detected emotions are not totally incoherent**. \n",
    "\n",
    "**However the first sample comes from the train data where it was initially labeled as neutral. The predictions made by our model make a little more sens in our opinion (it is of course very subjective)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wbWDq2ih0qq"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmYA0qoDh4qC"
   },
   "source": [
    "*   In our opinion, **focusing on the 7 emotions in Ekman taxonomy is not worth it** as we did not observe a significant shift from score we obtained using GoEmotions, compared to the amount of details we lost.\n",
    "\n",
    "*   This proves that there is a **promising margin for improvement** when it comes to detecting a large spectrum of emotions.\n",
    "\n",
    "*   **Some 'Neutral' training samples were not so 'Neutral'**. Let's see what we can do about that in the next notebook ...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_BERT_Model_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1452cca9f6044bb29988a30e16bd6512": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16ae3f272e7f48f1aa952facfa90103f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b84bc188e3a42a485e373a2f082eb62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2bf7f059050440aeae93abb56da42b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33c444e0f6db4bb889467904e4f5f373": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "399699282bb54551af159c7fd36e3308": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d00e9bb66e64d3b8a02b4e4dd7fa0ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8829af6fbe824bdea68c20f77832b273",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b84bc188e3a42a485e373a2f082eb62",
      "value": 466062
     }
    },
    "408795dbb77949c688a01ceb57cd79e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4449518347a34555b2e43c20f659368b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "462877f3796041f49f37ff8a64c691aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51b7374eaa984aca811ff234a88e69aa",
      "placeholder": "​",
      "style": "IPY_MODEL_5a6057df67dd44e0b623e071cbbea13e",
      "value": " 536M/536M [00:26&lt;00:00, 20.5MB/s]"
     }
    },
    "49bd642db157433a818e87ce344ca788": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c7cd71c58db4ff2b7fd4754d1329cb1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51b7374eaa984aca811ff234a88e69aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "526ed138b21243b8bb1372705ac54c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1452cca9f6044bb29988a30e16bd6512",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e530400c3d7944a9bb3de631be97c20c",
      "value": 28
     }
    },
    "56923b6b0cbb4684a339b4c8442d8218": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbe0a2e764b3451ea2c957da9c81e073",
       "IPY_MODEL_c1a0a146fb9e4fc6a84facf2083f7d98"
      ],
      "layout": "IPY_MODEL_4c7cd71c58db4ff2b7fd4754d1329cb1"
     }
    },
    "5a6057df67dd44e0b623e071cbbea13e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a902f789e6c4fdfb8278e217aaa1fd4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e380424f69d4fe48c21aa10a76d04df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60f8aefb1ef347d0a024233e44446e79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74d0060c2b26467aab98203f3b6e8862": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_408795dbb77949c688a01ceb57cd79e9",
      "placeholder": "​",
      "style": "IPY_MODEL_4449518347a34555b2e43c20f659368b",
      "value": " 232k/232k [00:00&lt;00:00, 262kB/s]"
     }
    },
    "7a28458037764a9e8f61db762ee76cc7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf4075f35ac43189f825750e6e31a37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8829af6fbe824bdea68c20f77832b273": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eb3aea2b7614e509b9442c4f12079e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a902f789e6c4fdfb8278e217aaa1fd4",
      "placeholder": "​",
      "style": "IPY_MODEL_5e380424f69d4fe48c21aa10a76d04df",
      "value": " 28.0/28.0 [00:00&lt;00:00, 67.9B/s]"
     }
    },
    "8f8c296ed2cf456f909c79d7494e5717": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d00e9bb66e64d3b8a02b4e4dd7fa0ec",
       "IPY_MODEL_df007a65916644b7a0e12be1486eb929"
      ],
      "layout": "IPY_MODEL_33c444e0f6db4bb889467904e4f5f373"
     }
    },
    "9d7b1e07c28b4cbba335b6cee88e837d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2f698fad1064038a7769c35fbe386c3",
       "IPY_MODEL_462877f3796041f49f37ff8a64c691aa"
      ],
      "layout": "IPY_MODEL_d94670a4d92d4ab3813fe383e72a8ce2"
     }
    },
    "a2f698fad1064038a7769c35fbe386c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_399699282bb54551af159c7fd36e3308",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc3375dda156477a8d88db87aa922728",
      "value": 536063208
     }
    },
    "ab7f06259de4475bb56ea30a587a0519": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3e5e15756314e028c70c8ad509b6d45",
       "IPY_MODEL_74d0060c2b26467aab98203f3b6e8862"
      ],
      "layout": "IPY_MODEL_2bf7f059050440aeae93abb56da42b1b"
     }
    },
    "b3e5e15756314e028c70c8ad509b6d45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49bd642db157433a818e87ce344ca788",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ee2f0e3c9c2e4413ba5eddb51a41eac0",
      "value": 231508
     }
    },
    "b6a33cd8ac9b402b92fdde2531784017": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdd01bb70693405fbc328fe08a95abb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_526ed138b21243b8bb1372705ac54c31",
       "IPY_MODEL_8eb3aea2b7614e509b9442c4f12079e5"
      ],
      "layout": "IPY_MODEL_60f8aefb1ef347d0a024233e44446e79"
     }
    },
    "c1a0a146fb9e4fc6a84facf2083f7d98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cf4075f35ac43189f825750e6e31a37",
      "placeholder": "​",
      "style": "IPY_MODEL_f94affeea44241bd893e765d3b2595b5",
      "value": " 433/433 [00:32&lt;00:00, 13.5B/s]"
     }
    },
    "c987eefbd5a8430db6f63acfe48101c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cc3375dda156477a8d88db87aa922728": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d94670a4d92d4ab3813fe383e72a8ce2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe0a2e764b3451ea2c957da9c81e073": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a28458037764a9e8f61db762ee76cc7",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c987eefbd5a8430db6f63acfe48101c0",
      "value": 433
     }
    },
    "df007a65916644b7a0e12be1486eb929": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16ae3f272e7f48f1aa952facfa90103f",
      "placeholder": "​",
      "style": "IPY_MODEL_b6a33cd8ac9b402b92fdde2531784017",
      "value": " 466k/466k [00:27&lt;00:00, 16.7kB/s]"
     }
    },
    "e530400c3d7944a9bb3de631be97c20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ee2f0e3c9c2e4413ba5eddb51a41eac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f94affeea44241bd893e765d3b2595b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
